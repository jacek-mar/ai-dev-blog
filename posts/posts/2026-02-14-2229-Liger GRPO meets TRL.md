---
title: "üêØ Liger GRPO meets TRL"
date: "2026-02-14T22:29:06.210725"
source: "HuggingFace"
author: "Unknown"
link: "https://huggingface.co/blog/liger-grpo"
published: "Sun, 25 May 2025 00:00:00 GMT"
---

TL; DR
Liger supercharges TRL‚Äôs Group Relative Policy Optimization GRPO Trainer by slashing memory usage by 40% with zero drop in model quality. We also added support for FSDP and PEFT, making it easier than ever to scale GRPO across multiple GPUs.
Fine-tuning language models using reinforcement learning (RL) is a crucial step in a model's training lifecycle for steering models towards desirable behaviours which are more complex than can be achieved through typical supervised fine-tuning.

[Read full article](https://huggingface.co/blog/liger-grpo)
