---
title: "Welcome EmbeddingGemma, Google's new efficient embedding model"
date: "2026-02-14T22:28:29.295654"
source: "HuggingFace"
author: "Unknown"
link: "https://huggingface.co/blog/embeddinggemma"
published: "Thu, 04 Sep 2025 00:00:00 GMT"
---

Today, Google releases EmbeddingGemma, a state-of-the-art multilingual embedding model perfect for on-device use cases. Designed for speed and efficiency, the model features a compact size of 308M parameters and a 2K context window, unlocking new possibilities for mobile RAG pipelines, agents, and more. EmbeddingGemma is trained to support over 100 languages and is the highest-ranking text-only multilingual embedding model under 500M on the Massive Text Embedding Benchmark (MTEB) at the time of ...

[Read full article](https://huggingface.co/blog/embeddinggemma)
