<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HuggingFace Articles - AI Developers Blog</title>
    <meta name="description" content="All articles from HuggingFace on AI Developers Blog">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    
        <nav class="main-nav">
            <div class="nav-container">
                <a href="index.html" class="nav-brand">AI Developers Blog</a>
                <div class="nav-links">
                    <a href="index.html" class="nav-link active">All Articles</a>
                    <div class="dropdown">
                        <button class="nav-link dropdown-btn">Sources ‚ñº</button>
                        <div class="dropdown-content">
                            <a href="sources/claude.html">Claude</a>
                            <a href="sources/google-cloud.html">Google Cloud</a>
                            <a href="sources/huggingface.html">HuggingFace</a>
                            <a href="sources/kilocode.html">KiloCode</a>
                            <a href="sources/kiro.html">Kiro</a>
                            <a href="sources/windsurf.html">Windsurf</a>
                            <a href="sources/zencoder.html">Zencoder</a>
                        </div>
                    </div>
                    <a href="feed.xml" class="nav-link">RSS</a>
                </div>
            </div>
        </nav>
        

    <header class="site-header">
        <h1>HuggingFace Articles</h1>
        <p class="site-description">20 articles from HuggingFace</p>
        <p><a href="../index.html">‚Üê Back to all sources</a></p>
    </header>

    <main class="container">
        <div class="articles-grid">

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Wed, 28 Jan 2026 00:00:00 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/we-got-claude-to-build-cuda-kernels-and-teach-open-models.html">We Got Claude to Build CUDA Kernels and teach open models!</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">The best thing about agent skills is upskilling your agents on hard problems. There are two ways to look at that: This blog post walks through the process of using a new tool, upskill, to generate and evaluate agent skills with large models and use them with smaller models....</p>
            <div class="card-footer">
                <a href="posts/we-got-claude-to-build-cuda-kernels-and-teach-open-models.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/upskill" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Wed, 21 Jan 2026 06:25:31 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/assetopsbench-bridging-the-gap-between-ai-agent-benchmarks-and-industrial-reality.html">AssetOpsBench: Bridging the Gap Between AI Agent Benchmarks and Industrial Reality</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">AssetOpsBench is a comprehensive benchmark and evaluation system with six qualitative dimensions that bridges the gap for agentic AI in domain-specific settings, starting with industrial Asset Lifecycle Management. While existing AI benchmarks excel at isolated tasks such as coding or web navigation...</p>
            <div class="card-footer">
                <a href="posts/assetopsbench-bridging-the-gap-between-ai-agent-benchmarks-and-industrial-reality.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/ibm-research/assetopsbench-playground-on-hugging-face" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Wed, 04 Feb 2026 15:00:40 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/nemotron-colembed-v2-raising-the-bar-for-multimodal-retrieval-with-vidore-v3s-top-model.html">Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3‚Äôs Top Model</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">Modern search systems are increasingly designed to process heterogeneous document images that may contain text, tables, charts, figures, and other visual components. In this context, accurately retrieving relevant information across these diverse modalities is a central challenge....</p>
            <div class="card-footer">
                <a href="posts/nemotron-colembed-v2-raising-the-bar-for-multimodal-retrieval-with-vidore-v3s-top-model.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/nvidia/nemotron-colembed-v2" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Wed, 04 Feb 2026 00:00:00 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/community-evals-because-were-done-trusting-black-box-leaderboards-over-the-community.html">Community Evals: Because we're done trusting black-box leaderboards over the community</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">TL;DR: Benchmark datasets on Hugging Face can now host leaderboards. Models store their own eval scores. The community can submit results via PR. Verified badges prove that the results can be reproduced. Let's be real about where we are with evals in 2026....</p>
            <div class="card-footer">
                <a href="posts/community-evals-because-were-done-trusting-black-box-leaderboards-over-the-community.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/community-evals" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Tue, 27 Jan 2026 15:01:45 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/architectural-choices-in-chinas-open-source-ai-ecosystem-building-beyond-deepseek.html">Architectural Choices in China's Open-Source AI Ecosystem: Building Beyond DeepSeek</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">This is the second blog in a three-part series on China's open source community's historical advancements since January 2025's "DeepSeek Moment." The first blog is available here, and the third blog is available here. In this second piece we turn our focus from models to the architectural and hardwa...</p>
            <div class="card-footer">
                <a href="posts/architectural-choices-in-chinas-open-source-ai-ecosystem-building-beyond-deepseek.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-2" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Tue, 27 Jan 2026 10:26:42 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/alyah-toward-robust-evaluation-of-emirati-dialect-capabilities-in-arabic-llms.html">Alyah ‚≠êÔ∏è: Toward Robust Evaluation of Emirati Dialect Capabilities in Arabic LLMs</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">üì¶ Dataset on HuggingFace | üîß Code on GitHub Arabic is one of the most widely spoken languages in the world, with hundreds of millions of speakers across more than twenty countries. Despite this global reach, Arabic is not a monolithic language....</p>
            <div class="card-footer">
                <a href="posts/alyah-toward-robust-evaluation-of-emirati-dialect-capabilities-in-arabic-llms.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/tiiuae/emirati-benchmarks" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Tue, 27 Jan 2026 01:53:15 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/unlocking-agentic-rl-training-for-gpt-oss-a-practical-retrospective.html">Unlocking Agentic RL Training for GPT-OSS: A Practical Retrospective</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">Agentic reinforcement learning (RL) extends traditional LLM training by optimizing not just a single-turn response, but an entire decision-making process learned through direct interaction with an environment during training....</p>
            <div class="card-footer">
                <a href="posts/unlocking-agentic-rl-training-for-gpt-oss-a-practical-retrospective.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/LinkedIn/gpt-oss-agentic-rl" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Tue, 20 Jan 2026 15:02:10 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/one-year-since-the-deepseek-moment.html">One Year Since the ‚ÄúDeepSeek Moment‚Äù</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">This is the first blog in a series that will examine China‚Äôs open source community‚Äôs historical advancements in the past year and its reverberations in shaping the entire ecosystem. Much of 2025‚Äôs progress can be traced back to January‚Äôs ‚ÄúDeepSeek Moment‚Äù, when Hangzhou-based AI company DeepSeek rel...</p>
            <div class="card-footer">
                <a href="posts/one-year-since-the-deepseek-moment.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Tue, 20 Jan 2026 03:20:57 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/differential-transformer-v2.html">Differential Transformer V2</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">Tianzhu Ye, Li Dong, Yutao Sun, Furu Wei Github Link Notion Link (for better readability) We introduce Differential Transformer V2 (DIFF V2), an improved version of Differential Transformer (DIFF V1). This revision focuses on inference efficiency, training stability for production-level LLMs, and ar...</p>
            <div class="card-footer">
                <a href="posts/differential-transformer-v2.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/microsoft/diff-attn-v2" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Tue, 20 Jan 2026 00:00:00 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/introducing-waypoint-1-real-time-interactive-video-diffusion-from-overworld.html">Introducing Waypoint-1: Real-time interactive video diffusion from Overworld</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">Overworld Stream: https://overworld.stream Waypoint-1 is Overworld‚Äôs real-time-interactive video diffusion model, controllable and prompted via text, mouse, and keyboard. You can give the model some frames, run the model, and have it create a world you can step into and interact with....</p>
            <div class="card-footer">
                <a href="posts/introducing-waypoint-1-real-time-interactive-video-diffusion-from-overworld.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/waypoint-1" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Tue, 03 Feb 2026 17:40:14 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/h-companys-new-holo2-model-takes-the-lead-in-ui-localization.html">H Company's new Holo2 model takes the lead in UI Localization</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">Two months since releasing our first batch of Holo2 models, H Company is back with our largest UI localization model yet: Holo2-235B-A22B Preview. This model achieves a new State-of-the-Art (SOTA) record of 78.5% on Screenspot-Pro and 79.0% on OSWorld G. Available on Hugging Face, Holo2-235B-A22B Pr...</p>
            <div class="card-footer">
                <a href="posts/h-companys-new-holo2-model-takes-the-lead-in-ui-localization.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Tue, 03 Feb 2026 15:03:19 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/the-future-of-the-global-open-source-ai-ecosystem-from-deepseek-to-ai.html">The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">This is the third and final blog in a three-part series on China's open source community's historical advancements since January 2025's "DeepSeek Moment." The first blog on strategic changes and open artifact growth is available here, and the second blog on architectural and hardware shifts is avail...</p>
            <div class="card-footer">
                <a href="posts/the-future-of-the-global-open-source-ai-ecosystem-from-deepseek-to-ai.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Tue, 03 Feb 2026 11:25:53 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/training-design-for-text-to-image-models-lessons-from-ablations.html">Training Design for Text-to-Image Models: Lessons from Ablations</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">This is the second part of our series on training efficient text-to-image models from scratch. In the first post of this series, we introduced our goal: training a competitive text-to-image foundation model entirely from scratch, in the open, and at scale. We focused primarily on architectural choic...</p>
            <div class="card-footer">
                <a href="posts/training-design-for-text-to-image-models-lessons-from-ablations.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/Photoroom/prx-part2" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Thu, 29 Jan 2026 00:00:00 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/introducing-daggr-chain-apps-programmatically-inspect-visually.html">Introducing Daggr: Chain apps programmatically, inspect visually</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">TL;DR: Daggr is a new, open-source Python library for building AI workflows that connect Gradio apps, ML models, and custom functions. It automatically generates a visual canvas where you can inspect intermediate outputs, rerun individual steps, and manage state for complex pipelines, all in a few l...</p>
            <div class="card-footer">
                <a href="posts/introducing-daggr-chain-apps-programmatically-inspect-visually.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/daggr" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Thu, 15 Jan 2026 00:00:00 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/open-responses-what-you-need-to-know.html">Open Responses: What you need to know</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">Open Responses is a new and open inference standard. Initiated by OpenAI, built by the open source AI community, and backed by the Hugging Face ecosystem, Open Responses is based on the Responses API and is designed for the future of Agents. In this blog post, we‚Äôll look at how Open Responses works ...</p>
            <div class="card-footer">
                <a href="posts/open-responses-what-you-need-to-know.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/open-responses" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Thu, 12 Feb 2026 00:00:00 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/openenv-in-practice-evaluating-tool-using-agents-in-real-world-environments.html">OpenEnv in Practice: Evaluating Tool-Using Agents in Real-World Environments</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">AI agents often perform impressively in controlled research settings, yet struggle when deployed in real-world systems where they must reason across multiple steps, interact with real tools and APIs, operate under partial information, and recover from errors in stateful, permissioned environments‚Äîhi...</p>
            <div class="card-footer">
                <a href="posts/openenv-in-practice-evaluating-tool-using-agents-in-real-world-environments.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/openenv-turing" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Thu, 05 Feb 2026 16:52:28 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/introducing-sygra-studio.html">Introducing SyGra Studio</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">SyGra 2.0.0 introduces Studio, an interactive environment that turns synthetic data generation into a transparent, visual craft. Instead of juggling YAML files and terminals, you compose flows directly on the canvas, preview datasets before committing, tune prompts with inline variable hints, and wa...</p>
            <div class="card-footer">
                <a href="posts/introducing-sygra-studio.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/ServiceNow-AI/sygra-studio" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Mon, 09 Feb 2026 00:00:00 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/transformersjs-v4-preview-now-available-on-npm.html">Transformers.js v4 Preview: Now Available on NPM!</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">We're excited to announce that Transformers.js v4 (preview) is now available on NPM! After nearly a year of development (we started in March 2025 ü§Ø), we're finally ready for you to test it out. Previously, users had to install v4 directly from source via GitHub, but now it's as simple as running a s...</p>
            <div class="card-footer">
                <a href="posts/transformersjs-v4-preview-now-available-on-npm.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/transformersjs-v4" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Mon, 05 Jan 2026 22:56:51 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/nvidia-cosmos-reason-2-brings-advanced-reasoning-to-physical-ai.html">NVIDIA Cosmos Reason 2 Brings Advanced Reasoning To Physical AI</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">NVIDIA today released Cosmos Reason 2, the latest advancement in open, reasoning vision language models for physical AI. Cosmos Reason 2 surpasses its previous version in accuracy and tops the Physical AI Bench and Physical Reasoning leaderboards as the #1 open model for visual understanding....</p>
            <div class="card-footer">
                <a href="posts/nvidia-cosmos-reason-2-brings-advanced-reasoning-to-physical-ai.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        

        <article class="article-card">
            <div class="card-header">
                <span class="source-badge" style="background-color: #FFD21E">HuggingFace</span>
                <span class="article-date">Fri, 13 Feb 2026 00:00:00 GMT</span>
            </div>
            <h2 class="article-title">
                <a href="posts/custom-kernels-for-all-from-codex-and-claude.html">Custom Kernels for All from Codex and Claude</a>
            </h2>
            <div class="article-meta">
                <span class="author">By Unknown</span>
            </div>
            <p class="article-summary">tl;dr: We built an agent skill that teaches coding agents how to write production CUDA kernels. Then we pointed Claude and Codex at two real targets: a diffusers pipeline and a transformers model. The agents produced working kernels for both, with correct PyTorch bindings and benchmarks, end to end....</p>
            <div class="card-footer">
                <a href="posts/custom-kernels-for-all-from-codex-and-claude.html" class="read-more">Read More ‚Üí</a>
                <a href="https://huggingface.co/blog/custom-cuda-kernels-agent-skills" class="external-link" target="_blank" rel="noopener">View Original ‚Üó</a>
            </div>
        </article>
        
        </div>
    </main>

    <footer class="site-footer">
        <p><a href="../index.html">Back to Home</a> ‚Ä¢ <a href="../feed.xml">RSS Feed</a></p>
    </footer>
</body>
</html>
